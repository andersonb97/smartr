<script>
  (async () => {
    const context = new AudioContext({ sampleRate: 16000 });
    await context.audioWorklet.addModule(URL.createObjectURL(new Blob([`
      class PCMWorklet extends AudioWorkletProcessor {
        process(inputs) {
          const input = inputs[0][0];
          const output = new Int16Array(input.length);
          for (let i = 0; i < input.length; i++) {
            output[i] = Math.max(-1, Math.min(1, input[i])) * 32767;
          }
          this.port.postMessage(output.buffer, [output.buffer]);
          return true;
        }
      }
      registerProcessor('pcm-worklet', PCMWorklet);
    `], { type: 'application/javascript' })));

    // Single playback AudioContext
    const audioCtx = new AudioContext({ sampleRate: 24000 });

    // Playback queue â€” a promise chain that serializes chunks
    let playQueue = Promise.resolve();

    const ws = new WebSocket("ws://localhost:8000/ws/audio");

    ws.onmessage = (event) => {
      console.log("Received message from server:", event);
      const data = JSON.parse(event.data);
      if (data.text) {
        console.log("GPT says:", data.text);
      }
      if (data.audio) {
        console.log("Received audio chunk (base64)", data.audio);
        enqueueAudio(data.audio);
      }
      if (data.done) {
        console.log("Response done");
      }
    };

    function enqueueAudio(base64) {
      playQueue = playQueue.then(() => playAudioFromBase64(base64));
    }

    // Returns a Promise that resolves after the audio chunk finishes playing
    function playAudioFromBase64(base64) {
      return new Promise(async (resolve) => {
        // Decode base64 to ArrayBuffer
        const raw = atob(base64);
        const len = raw.length;
        const buffer = new ArrayBuffer(len);
        const view = new Uint8Array(buffer);
        for (let i = 0; i < len; i++) {
          view[i] = raw.charCodeAt(i);
        }

        // Convert to Float32Array normalized samples
        const int16Array = new Int16Array(buffer);
        const float32Array = new Float32Array(int16Array.length);
        for (let i = 0; i < int16Array.length; i++) {
          float32Array[i] = int16Array[i] / 32768;
        }

        // Create AudioBuffer
        const audioBuffer = audioCtx.createBuffer(1, float32Array.length, audioCtx.sampleRate);
        audioBuffer.getChannelData(0).set(float32Array);

        // Setup BufferSource
        const source = audioCtx.createBufferSource();
        source.buffer = audioBuffer;
        source.connect(audioCtx.destination);

        // When playback ends, resolve the promise
        source.onended = () => {
          resolve();
        };

        // Start playback
        if (audioCtx.state === 'suspended') {
          await audioCtx.resume();
        }
        source.start();
      });
    }

    const mic = await navigator.mediaDevices.getUserMedia({
      audio: {
        echoCancellation: true,
        noiseSuppression: true,
      }
    });
    const source = context.createMediaStreamSource(mic);
    const node = new AudioWorkletNode(context, "pcm-worklet");

    node.port.onmessage = e => {
      const raw = new Uint8Array(e.data);
      console.log("Sending audio chunk length:", raw.length);
      ws.send(raw);
    };

    source.connect(node);
  })();
</script>
